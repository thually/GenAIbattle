from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field

from LIBS.WXlib import WX

app = FastAPI()

# Instantiate the wx object only ONCE in your application.
wx = WX()

# Set the model parameters or model name only if you want to change the model ID or its default parameters.
modelParameters = {
    "decoding_method": "greedy",
    "max_new_tokens": 2048,
    "min_new_tokens": 0,
    "stop_sequences": [ ],
    "repetition_penalty": 1
}
wx.wxInstModel(modelID='meta-llama/llama-3-70b-instruct', modelParams=modelParameters)

# Set the prompt template only once if you want to change the model behavior or expected output.
promptTemplate = """
    <|system|>
    You carefully follow instructions. You are helpful and harmless and you follow ethical guidelines and promote positive behavior.
    <|user|>
    {{QUESTION}}
    <|assistant|>
"""

# specify the expected structure and data types of the request body. 
# In this case, it expects a JSON object with a single field:
# question: str: A field named question that should be a string. 
class ApiQuestionRequest(BaseModel):
    # This is the only data your endpoint expects in incoming requests.
    question: str = Field(..., 
        example="Hi, how are you?",
        description="In this field, please enter a question in English to be passed to LLM."
    )

class ApiQuestionResponse(BaseModel):
    # This is the only data your endpoint returns in response.
    question: str = Field(..., 
        example="What is the value of a circle's area divided by pi, where the radius of a circle is 2?",
        description="In this field, the content of the original question submitted with the POST /api request will be returned."
    )
    answer: str = Field(..., 
        example="To find the value, you would first calculate the area of the circle , and then divide the result by Pi. The answer is 4.",
        description="In this field, the text generated by the Language Model will be displayed."
    )


# A decorator that creates a route for POST requests to the URL path /question/. 
# function generate_answer defined below is to be called when a POST request to /question/ is received
@app.post("/api/question")
async def apiQuestion(request: ApiQuestionRequest) -> ApiQuestionResponse:
    # Automatically parse the JSON body of incoming requests, validate them against the Question model,
    # and pass a Question instance to the function for access to the request body.

    # TODO: 
    # Begin your code block for LLM interaction.
    original_question = request.question
    my_answer = wx.wxGenText(promptTemplate=promptTemplate,
                             promptVariables={'QUESTION': original_question})
    # my_answer = f'Mock answer to your question: {original_question}'
    # End of your code block

    # Return response
    return ApiQuestionResponse(question=original_question, answer=my_answer)

